[[sec-vector-permute]]
== Vector Permutation Instructions

A range of permutation instructions are provided to move elements
around within the vector registers.

=== Integer Scalar Move Instructions

The integer scalar read/write instructions transfer a single
value between a scalar `x` register and element 0 of a vector
register.  The instructions ignore LMUL and vector register groups.

----
vmv.x.s rd, vs2  # x[rd] = vs2[0] (vs1=0)
vmv.s.x vd, rs1  # vd[0] = x[rs1] (vs2=0)
----

The `vmv.x.s` instruction copies a single SEW-wide element from index 0 of the
source vector register to a destination integer register.  If SEW > XLEN, the
least-significant XLEN bits are transferred and the upper SEW-XLEN bits are
ignored.  If SEW < XLEN, the value is sign-extended to XLEN bits.

NOTE: `vmv.x.s` performs its operation even if `vstart` {ge} `vl` or `vl`=0.

The `vmv.s.x` instruction copies the scalar integer register to element 0 of
the destination vector register.  If SEW < XLEN, the least-significant bits
are copied and the upper XLEN-SEW bits are ignored.  If SEW > XLEN, the value
is sign-extended to SEW bits.  The other elements in the destination vector
register ( 0 < index < VLEN/SEW) are treated as tail elements using the current tail agnostic/undisturbed policy.  If `vstart` {ge} `vl`, no
operation is performed and the destination register is not updated.

NOTE: As a consequence, when `vl`=0, no elements are updated in the
destination vector register group, regardless of `vstart`.

The encodings corresponding to the masked versions (`vm=0`) of `vmv.x.s`
and `vmv.s.x` are reserved.

=== Floating-Point Scalar Move Instructions

The floating-point scalar read/write instructions transfer a single
value between a scalar `f` register and element 0 of a vector
register.  The instructions ignore LMUL and vector register groups.

----
vfmv.f.s rd, vs2  # f[rd] = vs2[0] (rs1=0)
vfmv.s.f vd, rs1  # vd[0] = f[rs1] (vs2=0)
----

The `vfmv.f.s` instruction copies a single SEW-wide element from index
0 of the source vector register to a destination scalar floating-point
register.

NOTE: `vfmv.f.s` performs its operation even if `vstart` {ge} `vl` or `vl`=0.

The `vfmv.s.f` instruction copies the scalar floating-point register
to element 0 of the destination vector register.  The other elements
in the destination vector register ( 0 < index < VLEN/SEW) are treated
as tail elements using the current tail agnostic/undisturbed policy.
If `vstart` {ge} `vl`, no operation is performed and the destination
register is not updated.

NOTE: As a consequence, when `vl`=0, no elements are updated in the
destination vector register group, regardless of `vstart`.

The encodings corresponding to the masked versions (`vm=0`) of `vfmv.f.s`
and `vfmv.s.f` are reserved.

=== Vector Slide Instructions

The slide instructions move elements up and down a vector register
group.

NOTE: The slide operations can be implemented much more efficiently
than using the arbitrary register gather instruction.  Implementations
may optimize certain OFFSET values for `vslideup` and `vslidedown`.
In particular, power-of-2 offsets may operate substantially faster
than other offsets.

For all of the `vslideup`, `vslidedown`, `v[f]slide1up`, and
`v[f]slide1down` instructions, if `vstart` {ge} `vl`, the instruction performs no
operation and leaves the destination vector register unchanged.

NOTE: As a consequence, when `vl`=0, no elements are updated in the
destination vector register group, regardless of `vstart`.

The tail agnostic/undisturbed policy is followed for tail elements.

The slide instructions may be masked, with mask element _i_
controlling whether _destination_ element _i_ is written.  The mask
undisturbed/agnostic policy is followed for inactive elements.

==== Vector Slideup Instructions

----
 vslideup.vx vd, vs2, rs1, vm        # vd[i+rs1] = vs2[i]
 vslideup.vi vd, vs2, uimm, vm       # vd[i+uimm] = vs2[i]
----

For `vslideup`, the value in `vl` specifies the maximum number of destination
elements that are written.  The start index (_OFFSET_) for the
destination can be either specified using an unsigned integer in the
`x` register specified by `rs1`, or a 5-bit immediate, zero-extended to XLEN bits.
If XLEN > SEW, _OFFSET_ is _not_ truncated to SEW bits.
Destination elements _OFFSET_ through `vl`-1 are written if unmasked and
if _OFFSET_ < `vl`.

----
   vslideup behavior for destination elements

   OFFSET is amount to slideup, either from x register or a 5-bit immediate

                    0 <  i < max(vstart, OFFSET)  Unchanged
  max(vstart, OFFSET) <= i < vl                   vd[i] = vs2[i-OFFSET] if v0.mask[i] enabled
                   vl <= i < VLMAX                Follow tail policy
----

The destination vector register group for `vslideup` cannot overlap
the source vector register group, otherwise the instruction encoding
is reserved.

NOTE: The non-overlap constraint avoids WAR hazards on the
input vectors during execution, and enables restart with non-zero
`vstart`.

==== Vector Slidedown Instructions

----
 vslidedown.vx vd, vs2, rs1, vm       # vd[i] = vs2[i+rs1]
 vslidedown.vi vd, vs2, uimm, vm      # vd[i] = vs2[i+uimm]
----

For `vslidedown`, the value in `vl` specifies the maximum number of
destination elements that are written.  The remaining elements past
`vl` are handled according to the current tail policy (Section
<<sec-agnostic>>).

The start index (_OFFSET_) for the source can be either specified
using an unsigned integer in the `x` register specified by `rs1`, or a
5-bit immediate, zero-extended to XLEN bits.
If XLEN > SEW, _OFFSET_ is _not_ truncated to SEW bits.

----
  vslidedown behavior for source elements for element i in slide
                   0 <= i+OFFSET < VLMAX   src[i] = vs2[i+OFFSET]
               VLMAX <= i+OFFSET           src[i] = 0

  vslidedown behavior for destination element i in slide
                   0 <  i < vstart         Unchanged
              vstart <= i < vl             vd[i] = src[i] if v0.mask[i] enabled
                  vl <= i < VLMAX          Follow tail policy

----

==== Vector Slide1up

Variants of slide are provided that only move by one element but which
also allow a scalar integer value to be inserted at the vacated
element position.

----
 vslide1up.vx  vd, vs2, rs1, vm        # vd[0]=x[rs1], vd[i+1] = vs2[i]
 vfslide1up.vf vd, vs2, rs1, vm        # vd[0]=f[rs1], vd[i+1] = vs2[i]
----

The `vslide1up` instruction places the `x` register argument at
location 0 of the destination vector register group, provided that
element 0 is active, otherwise the destination element update follows the
current mask agnostic/undisturbed policy.  If XLEN < SEW, the value is
sign-extended to SEW bits.  If XLEN > SEW, the least-significant bits
are copied over and the high SEW-XLEN bits are ignored.

The remaining active `vl`-1 elements are copied over from index _i_ in
the source vector register group to index _i_+1 in the destination
vector register group.

The `vl` register specifies the maximum number of destination vector
register elements updated with source values, and remaining elements
past `vl` are handled according to the current tail policy (Section
<<sec-agnostic>>).


----
   vslide1up behavior

                    i < vstart  unchanged
                0 = i = vstart  vd[i] = x[rs1] if v0.mask[i] enabled
  max(vstart, 1) <= i < vl      vd[i] = vs2[i-1] if v0.mask[i] enabled
              vl <= i < VLMAX   Follow tail policy
----

The `vslide1up` instruction requires that the destination vector
register group does not overlap the source vector register group.
Otherwise, the instruction encoding is reserved.

The `vfslide1up` instruction is defined analogously, but sources its
scalar argument from an `f` register.

==== Vector Slide1down Instruction

The `vslide1down` instruction copies the first `vl`-1 active elements
values from index _i_+1 in the source vector register group to index
_i_ in the destination vector register group.

The `vl` register specifies the maximum number of destination vector
register elements written with source values, and remaining elements
past `vl` are handled according to the current tail policy (Section
<<sec-agnostic>>).

----
 vslide1down.vx  vd, vs2, rs1, vm      # vd[i] = vs2[i+1], vd[vl-1]=x[rs1]
 vfslide1down.vf vd, vs2, rs1, vm      # vd[i] = vs2[i+1], vd[vl-1]=f[rs1]
----

The `vslide1down` instruction places the `x` register argument at
location `vl`-1 in the destination vector register, provided that
element `vl-1` is active, otherwise the destination element is
unchanged. If XLEN < SEW, the value is sign-extended to SEW bits.  If
XLEN > SEW, the least-significant bits are copied over and the high
SEW-XLEN bits are ignored.

----
   vslide1down behavior

                       i < vstart  unchanged
             vstart <= i < vl-1    vd[i] = vs2[i+1] if v0.mask[i] enabled
             vstart <= i = vl-1    vd[vl-1] = x[rs1] if v0.mask[i] enabled
                 vl <= i < VLMAX   Follow tail policy
----

The `vfslide1down` instruction is defined analogously, but sources its
scalar argument from an `f` register.

NOTE: The `vslide1down` instruction can be used to load values into a
vector register without using memory and without disturbing other
vector registers.  This provides a path for debuggers to modify the
contents of a vector register, albeit slowly, with multiple repeated
`vslide1down` invocations.

=== Vector Register Gather Instructions

The vector register gather instructions read elements from a first
source vector register group at locations given by a second source
vector register group.  The index values in the second vector are
treated as unsigned integers.  The source vector can be read at any
index < VLMAX regardless of `vl`.  The maximum number of elements to write to
the destination register is given by `vl`, and the remaining elements
past `vl` are handled according to the current tail policy
(Section <<sec-agnostic>>).  The operation can be masked, and the mask
undisturbed/agnostic policy is followed for inactive elements.

----
vrgather.vv vd, vs2, vs1, vm # vd[i] = (vs1[i] >= VLMAX) ? 0 : vs2[vs1[i]];
vrgatherei16.vv vd, vs2, vs1, vm # vd[i] = (vs1[i] >= VLMAX) ? 0 : vs2[vs1[i]];
----

The `vrgather.vv` form uses SEW/LMUL for both the data and
indices. The `vrgatherei16.vv` form uses SEW/LMUL for the data in
`vs2` but EEW=16 and EMUL = (16/SEW)*LMUL for the indices in `vs1`.

NOTE: When SEW=8, `vrgather.vv` can only reference vector elements
0-255.  The `vrgatherei16` form can index 64K elements, and can also
be used to reduce the register capacity needed to hold indices when
SEW > 16.

If an element index is out of range ( `vs1[i]` {ge} VLMAX )
then zero is returned for the element value.

Vector-scalar and vector-immediate forms of the register gather are
also provided.  These read one element from the source vector at the
given index, and write this value to the active elements at the start
of the destination vector register. The index value in the scalar
register and the immediate, zero-extended to XLEN bits, are treated as
unsigned integers.  If XLEN > SEW, the index value is _not_ truncated
to SEW bits.

NOTE: These forms allow any vector element to be "splatted" to an entire vector.

----
vrgather.vx vd, vs2, rs1, vm # vd[i] = (x[rs1] >= VLMAX) ? 0 : vs2[x[rs1]]
vrgather.vi vd, vs2, uimm, vm # vd[i] = (uimm >= VLMAX) ? 0 : vs2[uimm]
----

For any `vrgather` instruction, the destination vector register group
cannot overlap with the source vector register groups, otherwise the
instruction encoding is reserved.

=== Vector Compress Instruction

The vector compress instruction allows elements selected by a vector
mask register from a source vector register group to be packed into
contiguous elements at the start of the destination vector register
group.

----
  vcompress.vm vd, vs2, vs1  # Compress into vd elements of vs2 where vs1 is enabled
----

The vector mask register specified by `vs1` indicates which of the
first `vl` elements of vector register group `vs2` should be extracted
and packed into contiguous elements at the beginning of vector
register `vd`. The remaining elements of `vd` are treated as tail
elements according to the current tail policy (Section
<<sec-agnostic>>).

----
    Example use of vcompress instruction

        1 1 0 1 0 0 1 0 1   v0
        8 7 6 5 4 3 2 1 0   v1
        1 2 3 4 5 6 7 8 9   v2

                                vcompress.vm v2, v1, v0
        1 2 3 4 8 7 5 2 0   v2
----

`vcompress` is encoded as an unmasked instruction (`vm=1`). The equivalent
masked instruction (`vm=0`) is reserved.

The destination vector register group cannot overlap the source vector
register group or the source mask register, otherwise the instruction
encoding is reserved.

A trap on a `vcompress` instruction is always reported with a
`vstart` of 0.  Executing a `vcompress` instruction with a non-zero
`vstart` raises an illegal instruction exception.

NOTE: Although possible, `vcompress` is one of the more difficult
instructions to restart with a non-zero `vstart`, so assumption is
implementations will choose not do that but will instead restart from
element 0.  This does mean elements in destination register after
`vstart` will already have been updated.

==== Synthesizing `vdecompress`

There is no inverse `vdecompress` provided, as this operation can be
readily synthesized using iota and a masked vrgather:

----
    Desired functionality of 'vdecompress'
      7 6 5 4 3 2 1 0     # vid

            e d c b a     # packed vector of 5 elements
      1 0 0 1 1 1 0 1     # mask vector of 8 elements
      p q r s t u v w     # destination register before vdecompress

      e q r d c b v a     # result of vdecompress 
----

----
     # v0 holds mask
     # v1 holds packed data
     # v11 holds input expanded vector and result
     viota.m v10, v0                 # Calc iota from mask in v0
     vrgather.vv v11, v1, v10, v0.t  # Expand into destination
----
----
   p q r s t u v w    # v11 destination register
         e d c b a    # v1 source vector
   1 0 0 1 1 1 0 1    # v0 mask vector

   4 4 4 3 2 1 1 0    # v10 result of viota.m
   e q r d c b v a    # v11 destination after vrgather using viota.m under mask
----

=== Whole Vector Register Move

The `vmv<nr>r.v` instructions copy whole vector registers (i.e., all
VLEN bits) and can copy whole vector register groups.  The
instructions operate as if EEW=SEW, EMUL = `nr`, effective length
`evl`= EMUL * VLEN/SEW.

NOTE: These instructions are intended to aid compilers to shuffle
vector registers without needing to know or change `vl` or `vtype`.

NOTE: The usual property that no elements are written if `vstart` {ge} `vl`
does not apply to these instructions.
Instead, no elements are written if `vstart` {ge} `evl`.

NOTE: If `vd` is equal to `vs2` the instruction is an architectural
NOP, but is treated as a hint to implementations that rearrange data
internally that the register group will next be accessed with an EEW
equal to SEW.

The instruction is encoded as an OPIVI instruction.  The number of
vector registers to copy is encoded in the low three bits of the
`simm` field using the same encoding as the `nf` field for memory
instructions, i.e., `simm` = `nr-1`.
The value of the `nr` field must be 1, 2, 4, or 8, with other values reserved.

NOTE: A future extension may support other numbers of registers to be moved.
Values of `simm` other than 0, 1, 3, and 7 are currently reserved.

NOTE: The instruction uses the same funct6 encoding as the `vsmul`
instruction but with an immediate operand, and only the unmasked
version (`vm=1`).  This encoding is chosen as it is close to the
related `vmerge` encoding, and it is unlikely the `vsmul` instruction
would benefit from an immediate form.

----
    vmv<nr>r.v vd, vs2  # General form

    vmv1r.v v1, v2   #  Copy v1=v2
    vmv2r.v v10, v12 #  Copy v10=v12; v11=v13
    vmv4r.v v4, v8   #  Copy v4=v8; v5=v9; v6=v10; v7=v11
    vmv8r.v v0, v8   #  Copy v0=v8; v1=v9; ...;  v7=v15
----

The source and destination vector register numbers must be aligned
appropriately for the vector register group size, and encodings with
other vector register numbers are reserved.

NOTE: A future extension may relax the vector register alignment
restrictions.
